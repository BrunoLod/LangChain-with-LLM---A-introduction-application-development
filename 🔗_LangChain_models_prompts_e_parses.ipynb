{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Apresentação ✒️\n",
        "\n",
        "Notebook destinado ao estudo do framework LangChain. Nesse primeiro momento, irei estudar sobre modelos de uso, prompts e parses, que podem modulam a saída de resposta da LLM a partir do framework."
      ],
      "metadata": {
        "id": "BWtSTy8t1ueD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bibliotecas 📚"
      ],
      "metadata": {
        "id": "kIFOng3B2GwQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dQkgXWbb1bX0"
      },
      "outputs": [],
      "source": [
        "!pip install google-generativeai -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hfi41mMX2sat",
        "outputId": "be4d0868-efcc-40c7-9b79-18e25e851c05"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/974.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m972.8/974.6 kB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m974.6/974.6 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m321.8/321.8 kB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.4/127.4 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.0/145.0 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_google_genai -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oOi1bX733NOE",
        "outputId": "f53c7aa6-6f70-4fb5-f3b1-525b75e8fa32"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/163.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.1/163.1 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/717.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m358.4/717.3 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m717.3/717.3 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import google.generativeai as genai\n",
        "\n",
        "import os\n",
        "import langchain\n",
        "\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "from langchain.output_parsers import ResponseSchema\n",
        "from langchain.output_parsers import StructuredOutputParser"
      ],
      "metadata": {
        "id": "5l9MU7wr2sn4"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['GOOGLE_API_KEY'] = 'sua-api-key'"
      ],
      "metadata": {
        "id": "4ginZGO93eqY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "genai.configure(api_key=os.environ['GOOGLE_API_KEY'])"
      ],
      "metadata": {
        "id": "n6fqJwRM3rmc"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instanciando a LLM de uso 🤖"
      ],
      "metadata": {
        "id": "6UZH_il3359i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Criando o modelo de llm utilizado com o google gemini.\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model = \"gemini-1.5-pro-latest\",\n",
        "    temperature = 0.8\n",
        ")"
      ],
      "metadata": {
        "id": "4avuiZ8u3uo2"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Templates\n",
        "\n",
        "Uma das vantagens que o framework oferece é elaborar templates (formatação) de mensagens, por meio das quais ajuda a prover a automatização de mensagens, modulando-as num formato desejado, segundo o seu contexto de uso.\n",
        "\n",
        "Tomamos como exemplo um cliente que escreve um e-mail em resposta ao seu fornecedor pouco profissionai. O objetivo é transformar a sua mensagem em algo profissional, em ordem de não produzir antipatia, mas ainda informar a sua perspectiva acerca de sua insatisfação."
      ],
      "metadata": {
        "id": "cYCYLL9K4o8p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "template_string = \"\"\"Deixe o texto \\\n",
        "que está delimitado por três crases \\\n",
        "em um estilo que seja {style}. \\\n",
        "texto : ```{text}```\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "-cN0Rzkd33ou"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "customer_style = \"\"\" Português brasileiro num tom que seja \\\n",
        "calmo, respeitoso e profissional.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "xLQojPWD51dY"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "customer_email = \"\"\"Arrr, estou furioso porque a tampa do meu liquidificador \\\n",
        "saiu voando e espalhou smoothie nas paredes da minha cozinha! \\\n",
        "E para piorar as coisas, a garantia não cobre o custo de \\\n",
        "limpar minha cozinha. Preciso da sua ajuda \\\n",
        "agora mesmo, camarada!\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Dtxkzy8H6N1m"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = ChatPromptTemplate.from_template(template_string)"
      ],
      "metadata": {
        "id": "oUo5J_Ku6puN"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "customer_messages = prompt_template.format_messages(\n",
        "    style = customer_style,\n",
        "    text = customer_email\n",
        ")"
      ],
      "metadata": {
        "id": "Ei1ANB7O7Kgl"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(customer_messages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-arrse-Z7amg",
        "outputId": "04f068e6-4b63-4898-9e9c-c7802bff70df"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[HumanMessage(content='Deixe o texto que está delimitado por três crases \\\\ \\nem um estilo que seja  Português brasileiro num tom que seja calmo, respeitoso e profissional.\\n. texto : ```Arrr, estou furioso porque a tampa do meu liquidificador saiu voando e espalhou smoothie nas paredes da minha cozinha! E para piorar as coisas, a garantia não cobre o custo de limpar minha cozinha. Preciso da sua ajuda agora mesmo, camarada!\\n```\\n')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(customer_messages))\n",
        "print(type(customer_messages[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HA7WZiFJ7TJJ",
        "outputId": "377a1cff-1795-4ac5-ba7e-c42ee117ceb5"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'>\n",
            "<class 'langchain_core.messages.human.HumanMessage'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Requisitando a LLM para traduzir o texto do cliente\n",
        "# para um formato que seja repeitoso.\n",
        "\n",
        "customer_response = llm(customer_messages)"
      ],
      "metadata": {
        "id": "VBaktUzF7U9V"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "customer_response.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "QLz7LLNt7xQW",
        "outputId": "d04b68b1-b93f-461c-b081-3be29691a579"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\"Olá, boa tarde. Gostaria de manifestar minha frustração com um problema que ocorreu com meu liquidificador. A tampa se soltou durante o uso, causando um pequeno acidente na minha cozinha. Infelizmente, a garantia não cobre os custos de limpeza. Solicito gentilmente uma solução para este inconveniente. Agradeço a atenção.\" \\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Formatando saídas\n",
        "\n",
        "Podemos formatar a saída que a LLM nos retorna, especificando um formato através do qual ela deve seguir. Por exemplo, essa abordagem é útil quando pretende-se regularizar as saídas difusas da LLM para um padrão mais regular, como formatação JSON, na qual por meio de chaves e seus valores, consegue-se compreender as informações geradas sob um ponto de vista sintético, mas igualmente informativo.\n",
        "\n",
        "Nessa etapa irei querer compreender o review de um cliente sob 4 parâmetros determinados, estruturados numa formatação JSON, como a seguir :      \n",
        "\n",
        "```\n",
        "{\n",
        "  \"gift\": False,\n",
        "  \"delivery_days\": 5,\n",
        "  \"price_value\": \"pretty affordable!\"\n",
        "  \"sentiment\": \"happy\"\n",
        "}\n",
        "```"
      ],
      "metadata": {
        "id": "7DGi8H2oAOmb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "customer_review = \"\"\"\\\n",
        "This leaf blower is pretty amazing.  It has four settings:\\\n",
        "candle blower, gentle breeze, windy city, and tornado. \\\n",
        "It arrived in two days, just in time for my wife's \\\n",
        "anniversary present. \\\n",
        "I think my wife liked it so much she was speechless. \\\n",
        "So far I've been the only one using it, and I've been \\\n",
        "using it every other morning to clear the leaves on our lawn. \\\n",
        "It's slightly more expensive than the other leaf blowers \\\n",
        "out there, but I think it's worth it for the extra features.\n",
        "\"\"\"\n",
        "\n",
        "review_template = \"\"\"\\\n",
        "Para o seguinte texto extraia as seguintes informações :\n",
        "\n",
        "presente: O item foi comprado como um presente para outra pessoa? \\\n",
        "Responda Verdadeiro se sim, Falso se não ou se desconhecido.\n",
        "\n",
        "dias_entrega: Quantos dias levou para o produto \\\n",
        "chegar? Se essa informação não for encontrada, insira -1.\n",
        "\n",
        "valor_preco: Extraia quaisquer frases sobre o valor ou preço, \\\n",
        "e coloque-as como uma lista Python separada por vírgulas.\n",
        "\n",
        "sentimento_presente : Extraia o sentimento presente do texto, como \\\n",
        "positivo, negativo ou neutro, com uma breve explicação sobre \\\n",
        "cada qual, que ilustra o sentimento presente do cliente.\n",
        "\n",
        "Formate a saída como JSON com as seguintes chaves e, se necessário, traduza \\\n",
        "o texto para português :\n",
        "\n",
        "presente\n",
        "dias_entrega\n",
        "valor_preco\n",
        "sentimento_presente\n",
        "\n",
        "text: {text}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "ZvoEw9Xl78-E"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_review_template = ChatPromptTemplate.from_template(review_template)"
      ],
      "metadata": {
        "id": "kdy4dJkvBzG7"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(prompt_review_template)\n",
        "print(\"\")\n",
        "print(type(prompt_review_template))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aK8sprzpDFRP",
        "outputId": "1485b85b-e391-45c0-9e9e-5118d0f1b1c1"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_variables=['text'] messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['text'], template='Para o seguinte texto extraia as seguintes informações :\\n\\npresente: O item foi comprado como um presente para outra pessoa? Responda Verdadeiro se sim, Falso se não ou se desconhecido.\\n\\ndias_entrega: Quantos dias levou para o produto chegar? Se essa informação não for encontrada, insira -1.\\n\\nvalor_preco: Extraia quaisquer frases sobre o valor ou preço, e coloque-as como uma lista Python separada por vírgulas.\\n\\nsentimento_presente : Extraia o sentimento presente do texto, como positivo, negativo ou neutro, com uma breve explicação sobre cada qual, que ilustra o sentimento presente do cliente.\\n\\nFormate a saída como JSON com as seguintes chaves e, se necessário, traduza \\\\ \\no texto para português :\\n\\npresente\\ndias_entrega\\nvalor_preco\\nsentimento_presente\\n\\ntext: {text}\\n'))]\n",
            "\n",
            "<class 'langchain_core.prompts.chat.ChatPromptTemplate'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages = prompt_review_template.format_messages(\n",
        "    text = customer_review\n",
        ")"
      ],
      "metadata": {
        "id": "biBtJckyDGxN"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "customer_response = llm(messages)"
      ],
      "metadata": {
        "id": "vFwE116mDbxn"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "customer_response.content\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "JHeR2yl5DetW",
        "outputId": "91d98179-e5f1-4491-cda5-8870bd80f0fd"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'```json\\n{\\n\"presente\": true,\\n\"dias_entrega\": 2,\\n\"valor_preco\": [\\n\"ligeiramente mais caro que os outros sopradores de folhas\",\\n\"vale a pena pelo recursos extras\"\\n],\\n\"sentimento_presente\": {\\n\"classificacao\": \"positivo\",\\n\"explicacao\": \"O cliente expressa satisfação com o soprador de folhas, descrevendo-o como \\'incrível\\' e destacando suas funcionalidades. Ele também menciona que o produto chegou a tempo para o aniversário de sua esposa e que acredita que ela tenha gostado muito.\"\\n}\\n}\\n```'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Formatando a saída para um dicionário em Python"
      ],
      "metadata": {
        "id": "oVzutTxMF541"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Criando uma formatação de resposta para a saída da LLM.\n",
        "\n",
        "gift_schema = ResponseSchema(name=\"gift\",\n",
        "                             description=\"Was the item purchased\\\n",
        "                             as a gift for someone else? \\\n",
        "                             Answer True if yes,\\\n",
        "                             False if not or unknown.\")\n",
        "\n",
        "delivery_days_schema = ResponseSchema(name=\"delivery_days\",\n",
        "                                      description=\"How many days\\\n",
        "                                      did it take for the product\\\n",
        "                                      to arrive? If this \\\n",
        "                                      information is not found,\\\n",
        "                                      output -1.\")\n",
        "\n",
        "price_value_schema = ResponseSchema(name=\"price_value\",\n",
        "                                    description=\"Extract any\\\n",
        "                                    sentences about the value or \\\n",
        "                                    price, and output them as a \\\n",
        "                                    comma separated Python list.\")\n",
        "\n",
        "price_sentiment_schema = ResponseSchema(name = \"sentiment\",\n",
        "                                        description=\"Extract the prevalent sentiment \\\n",
        "                                        from customer review, as positive, neutral or negative \\\n",
        "                                        with a short explication about it each one\")\n"
      ],
      "metadata": {
        "id": "dg-0hkWODkhG"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Criando uma lista com os formatos que a LLM deverá seguir, em ordem\n",
        "# de prover cada resposta na formatação correta.\n",
        "\n",
        "response_schemas = [gift_schema,\n",
        "                    delivery_days_schema,\n",
        "                    price_value_schema,\n",
        "                    price_sentiment_schema]"
      ],
      "metadata": {
        "id": "fJnv1_1bGdlW"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)"
      ],
      "metadata": {
        "id": "_ktjtLTKGrzK"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtendo o formato de de intrução que a LLM deverá seguir.\n",
        "\n",
        "format_instructions = output_parser.get_format_instructions()"
      ],
      "metadata": {
        "id": "lWHPehWsHDmR"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "review_template_2 = \"\"\"\\\n",
        "Para o seguinte texto extraia as seguintes informações :\n",
        "\n",
        "presente: O item foi comprado como um presente para outra pessoa? \\\n",
        "Responda Verdadeiro se sim, Falso se não ou se desconhecido.\n",
        "\n",
        "dias_entrega: Quantos dias levou para o produto \\\n",
        "chegar? Se essa informação não for encontrada, insira -1.\n",
        "\n",
        "valor_preco: Extraia quaisquer frases sobre o valor ou preço, \\\n",
        "e coloque-as como uma lista Python separada por vírgulas.\n",
        "\n",
        "sentimento_presente : Extraia o sentimento presente do texto, como \\\n",
        "positivo, negativo ou neutro, com uma breve explicação sobre \\\n",
        "cada qual, que ilustra o sentimento presente do cliente.\n",
        "\n",
        "texto : {text}\n",
        "\n",
        "{format_instructions}\n",
        "\n",
        "Faça com que o idioma do texto de saída seja português.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "4qZZ0hUbIevz"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = ChatPromptTemplate.from_template(template=review_template_2)\n",
        "\n",
        "messages = prompt.format_messages(text=customer_review,\n",
        "                                format_instructions=format_instructions)"
      ],
      "metadata": {
        "id": "rWp2DSDcJODY"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = llm(messages)"
      ],
      "metadata": {
        "id": "aMt4VbBeJflm"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "w-42x8YXJhtM",
        "outputId": "f60712ab-20ee-47a2-94f9-5a507c811059"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'```json\\n{\\n\\t\"gift\": \"True\",\\n\\t\"delivery_days\": \"2\",\\n\\t\"price_value\": \"[\\'É um pouco mais caro do que os outros sopradores de folhas por aí, mas acho que vale a pena pelos recursos extras.\\']\",\\n\\t\"sentiment\": \"positivo - O cliente expressa satisfação com o produto, descrevendo-o como \\'incrível\\' e mencionando que sua esposa gostou muito. Ele também destaca os aspectos positivos do produto, como as diferentes configurações e a eficácia na limpeza das folhas.\"\\n}\\n```'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_dict = output_parser.parse(response.content)"
      ],
      "metadata": {
        "id": "f2kv8OD5JpS-"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gerando a resposta numa saída em dicionário Python\n",
        "\n",
        "output_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dxutInTL8K-",
        "outputId": "46ca47b0-0cbf-45ff-d305-a60e7ce1e4dd"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'gift': 'True',\n",
              " 'delivery_days': '2',\n",
              " 'price_value': \"['É um pouco mais caro do que os outros sopradores de folhas por aí, mas acho que vale a pena pelos recursos extras.']\",\n",
              " 'sentiment': \"positivo - O cliente expressa satisfação com o produto, descrevendo-o como 'incrível' e mencionando que sua esposa gostou muito. Ele também destaca os aspectos positivos do produto, como as diferentes configurações e a eficácia na limpeza das folhas.\"}"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7X7Ooh1ZL9Hf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}